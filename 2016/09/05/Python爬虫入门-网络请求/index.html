<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="喜欢在夜深人静的时候敲键盘"><title>Python爬虫入门-网络请求 | Coding Pub</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/3.0.3/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫入门-网络请求</h1><a id="logo" href="/.">Coding Pub</a><p class="description">猎户座</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/guestbook/"><i class="fa fa-comments"> 留言</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫入门-网络请求</h1><div class="post-meta">Sep 5, 2016<span> | </span><span class="category"><a href="/categories/Python/">Python</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2016/09/05/Python爬虫入门-网络请求/" href="/2016/09/05/Python爬虫入门-网络请求/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#URL-Operation"><span class="toc-number">1.</span> <span class="toc-text">URL Operation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#编码-amp-解码"><span class="toc-number">1.1.</span> <span class="toc-text">编码 & 解码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#解析-URL"><span class="toc-number">1.2.</span> <span class="toc-text">解析 URL</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#发起请求"><span class="toc-number">2.</span> <span class="toc-text">发起请求</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Request-Header"><span class="toc-number">2.1.</span> <span class="toc-text">Request Header</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Request-Body"><span class="toc-number">2.2.</span> <span class="toc-text">Request Body</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MD5"><span class="toc-number">2.3.</span> <span class="toc-text">MD5</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Response-Header"><span class="toc-number">2.4.</span> <span class="toc-text">Response Header</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据解析"><span class="toc-number">2.5.</span> <span class="toc-text">数据解析</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Cookie"><span class="toc-number">3.</span> <span class="toc-text">Cookie</span></a></li></ol></div></div><div class="post-content"><p>介绍了许多语法基础，我们终于可以进入爬虫开发的正文了，就爬虫工具而言，Python对比于其他的语言有很大的优势，它内置的模块提供了强大的网络请求、数据处理功能。</p>
<a id="more"></a>
<h1 id="URL-Operation"><a href="#URL-Operation" class="headerlink" title="URL Operation"></a>URL Operation</h1><p>URL 作为网络请求最基础的部分，这里需要介绍一下 Python 的 URL 处理。</p>
<h2 id="编码-amp-解码"><a href="#编码-amp-解码" class="headerlink" title="编码 &amp; 解码"></a>编码 &amp; 解码</h2><figure class="highlight gcode"><table><tr><td class="code"><pre><div class="line">url = <span class="string">'https://www.test.com/photos?order_by=latest&amp;page=%d&amp;per_page=%d'</span> <span class="meta">%</span> <span class="comment">(pageIndex, pageSize)</span></div></pre></td></tr></table></figure>
<p>这是最简单的字符串拼接方式，在前面也有提过，不再展开。</p>
<p>假如我们有一个dict需要转成 URL 的 query 字符串，可以使用下面的方法：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><div class="line">&gt;&gt;&gt; import urllib.parse</div><div class="line">&gt;&gt;&gt;</div><div class="line">&gt;&gt;&gt; <span class="keyword">values</span> = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</div><div class="line">...           <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</div><div class="line">...           <span class="string">'title'</span>: <span class="string">'标题'</span>,</div><div class="line">...           <span class="string">'sourceId'</span>: <span class="number">10</span>,</div><div class="line">...           <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</div><div class="line">&gt;&gt;&gt;</div><div class="line">&gt;&gt;&gt; query = urllib.parse.urlencode(<span class="keyword">values</span>)</div><div class="line">&gt;&gt;&gt; <span class="keyword">print</span>(query)</div><div class="line">action=InsertPicReptile&amp;sourceId=<span class="number">10</span>&amp;title=%E6%A0%87%E9%A2%98&amp;url=http%3A%2F%2Fwww.google.com&amp;uniqueId=<span class="number">1122</span></div></pre></td></tr></table></figure>
<p>你是不是注意到有一些字符被自动转码为带有<code>%</code>的格式，除了这个，urllib.parse 还提供了其他的方法：</p>
<ul>
<li><p>quote(string, safe=’/‘, encoding=None, errors=None)</p>
<p>  对字符串进行编码，参数 safe 指定了不需要编码的字符</p>
</li>
<li><p>unquote(string, encoding=’utf-8’, errors=’replace’)</p>
<p>  对字符串进行解码</p>
</li>
<li><p>quote_plus(string, safe=’’, encoding=None, errors=None)</p>
<p>  与 quote 类似，但这个方法用<code>&#39;+&#39;</code>来替换<code>&#39; &#39;</code>，而 quote 用<code>&#39;%20&#39;</code>来代替<code>&#39; &#39;</code></p>
</li>
<li><p>unquote_plus(string, encoding=’utf-8’, errors=’replace’)</p>
<p>  对字符串进行解码</p>
</li>
<li><p>urlencode(query, doseq=False, safe=’’, encoding=None, errors=None, quote_via=<function quote_plus="" at="" 0x10147ff28="">)</function></p>
<p>  将dict或者包含两个元素的元组列表转换成url参数</p>
</li>
</ul>
<h2 id="解析-URL"><a href="#解析-URL" class="headerlink" title="解析 URL"></a>解析 URL</h2><figure class="highlight ruby"><table><tr><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;</span>&gt; from urllib import parse</div><div class="line"><span class="meta">&gt;&gt;</span>&gt;</div><div class="line">&gt;&gt;&gt; url = <span class="string">"http://www.baidu.com/s?wd=codeif.com&amp;rsv_spt=1&amp;issp=1&amp;rsv_bp=0&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_sug3=4&amp;rsv_sug=1&amp;rsv_sug1=3&amp;rsv_sug4=74"</span></div><div class="line"><span class="meta">&gt;&gt;</span>&gt; o = parse.urlparse(url)</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; print(<span class="string">'URL detail:'</span>, o)</div><div class="line">URL <span class="symbol">detail:</span> ParseResult(scheme=<span class="string">'http'</span>, netloc=<span class="string">'www.baidu.com'</span>, path=<span class="string">'/s'</span>, params=<span class="string">''</span>, query=<span class="string">'wd=codeif.com&amp;rsv_spt=1&amp;issp=1&amp;rsv_bp=0&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_sug3=4&amp;rsv_sug=1&amp;rsv_sug1=3&amp;rsv_sug4=74'</span>, fragment=<span class="string">''</span>)</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; params = parse.parse_qs(o.query)</div><div class="line"><span class="meta">&gt;&gt;</span>&gt; print(<span class="string">'URL query:'</span>, params)</div><div class="line">URL <span class="symbol">query:</span> &#123;<span class="string">'rsv_spt'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_sug3'</span>: [<span class="string">'4'</span>], <span class="string">'ie'</span>: [<span class="string">'utf-8'</span>], <span class="string">'issp'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_bp'</span>: [<span class="string">'0'</span>], <span class="string">'rsv_sug4'</span>: [<span class="string">'74'</span>], <span class="string">'tn'</span>: [<span class="string">'baiduhome_pg'</span>], <span class="string">'wd'</span>: [<span class="string">'codeif.com'</span>], <span class="string">'rsv_sug'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_sug1'</span>: [<span class="string">'3'</span>]&#125;</div></pre></td></tr></table></figure>
<h1 id="发起请求"><a href="#发起请求" class="headerlink" title="发起请求"></a>发起请求</h1><p>一个完整的网络请求、解析过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</div><div class="line"><span class="keyword">import</span> json</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">requestUnsplash</span><span class="params">(pageIndex, pageSize)</span>:</span></div><div class="line">    url = <span class="string">'https://unsplash.com/napi/photos?order_by=latest&amp;page=%d&amp;per_page=%d'</span> % (pageIndex, pageSize)</div><div class="line"></div><div class="line">    headers = &#123;<span class="string">'accept-version'</span>: <span class="string">'v1'</span>,</div><div class="line">               <span class="string">'authorization'</span>: <span class="string">'Client-ID d69927c7ea5c770fa2ce9a2f1e3589bd896454f7068f689d8e41a25b54fa6042'</span>,</div><div class="line">               <span class="string">'Referer'</span>: <span class="string">'https://unsplash.com/new'</span>,</div><div class="line">               <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'</span>&#125;</div><div class="line"></div><div class="line">    req = request.Request(url, data=<span class="keyword">None</span>, headers=headers, origin_req_host=<span class="keyword">None</span>, unverifiable=<span class="keyword">False</span>, method=<span class="keyword">None</span>)</div><div class="line"></div><div class="line">    <span class="keyword">with</span> request.urlopen(req) <span class="keyword">as</span> f:</div><div class="line">        response = f.read().decode(<span class="string">'utf-8'</span>)</div><div class="line">        <span class="comment"># print(f.info())</span></div><div class="line">        <span class="keyword">return</span> json.loads(response)</div><div class="line"></div><div class="line"><span class="comment"># print(requestUnsplash(1, 5))</span></div></pre></td></tr></table></figure>
<h2 id="Request-Header"><a href="#Request-Header" class="headerlink" title="Request Header"></a>Request Header</h2><p>从上面的代码可以到在初始化 Request 的时候可以传递 headers、data 参数，其中 header 是 dict 对象，data 是 body 编码后的 bytes 数据。</p>
<p>在初始化 Request 之后，还可以通过下面的方法设置 Header 参数。</p>
<figure class="highlight ceylon"><table><tr><td class="code"><pre><div class="line">req.add<span class="number">_</span>header(kye, <span class="keyword">value</span>)</div></pre></td></tr></table></figure>
<h2 id="Request-Body"><a href="#Request-Body" class="headerlink" title="Request Body"></a>Request Body</h2><p>要传递的 body 可以是表单形式，也可以是 json 格式，最终都是字符串编码为 bytes 数据流，文件表单这里不做讨论，用的比较少。</p>
<ul>
<li><p>表单形式的 body</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</div><div class="line">&gt;&gt;&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>values = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'title'</span>: <span class="string">'标题'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'sourceId'</span>: <span class="number">10</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>body = parse.urlencode(values)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>data = body.encode(<span class="string">'utf-8'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(data)</div><div class="line"><span class="string">b'action=InsertPicReptile&amp;sourceId=10&amp;title=%E6%A0%87%E9%A2%98&amp;url=http%3A%2F%2Fwww.google.com&amp;uniqueId=1122'</span></div></pre></td></tr></table></figure>
</li>
<li><p>json 形式的 body</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> json</div><div class="line">&gt;&gt;&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>values = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'title'</span>: <span class="string">'标题'</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'sourceId'</span>: <span class="number">10</span>,</div><div class="line"><span class="meta">... </span>          <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>body = json.dumps(values)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>data = body.encode(<span class="string">'utf-8'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(data)</div><div class="line"><span class="string">b'&#123;"action": "InsertPicReptile", "sourceId": 10, "title": "\\u6807\\u9898", "url": "http://www.google.com", "uniqueId": 1122&#125;'</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="MD5"><a href="#MD5" class="headerlink" title="MD5"></a>MD5</h2><p>接口请求经常会在Header或URL参数上增加校验参数，MD5加密算法是比较常用的不对成加密算法。Python已经封装了常用的加密算法，这里以MD5为例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import hashlib</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; md5Str = <span class="string">'key=hello'</span></span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sign = hashlib.md5(md5Str.encode(<span class="string">'utf-8'</span>)).hexdigest()</span></div><div class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span>(sign)</span></div><div class="line">5be7dcd8127f86af33182c778f27a185</div></pre></td></tr></table></figure>
<h2 id="Response-Header"><a href="#Response-Header" class="headerlink" title="Response Header"></a>Response Header</h2><p>前文完整的请求示例中屏蔽掉的 <code>print(f.info())</code> 可以用于获取 HTTP 请求的 Response Header。</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><div class="line"># 提取 Header 信息</div><div class="line">resHeaders = <span class="keyword">f</span>.info()</div><div class="line"><span class="built_in">keys</span> = resHeaders.<span class="built_in">keys</span>()</div><div class="line"><span class="built_in">values</span> = resHeaders.<span class="built_in">values</span>()</div><div class="line"><span class="built_in">items</span> = resHeaders.<span class="built_in">items</span>()</div><div class="line"><span class="keyword">print</span>(<span class="string">'keys:'</span>, <span class="built_in">keys</span>, <span class="string">'\n'</span>)</div><div class="line"><span class="keyword">print</span>(<span class="string">'values:'</span>, <span class="built_in">values</span>, <span class="string">'\n'</span>)</div><div class="line"><span class="keyword">print</span>(<span class="string">'items:'</span>, <span class="built_in">items</span>, <span class="string">'\n'</span>)</div><div class="line"></div><div class="line"># 提取 HTTP 请求状态码</div><div class="line"><span class="keyword">print</span>(<span class="string">'status:'</span>, <span class="keyword">f</span>.getcode())</div></pre></td></tr></table></figure>
<h2 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h2><p>body 读取出来是 bytes 数据，需要经过编码转成 str，目前主流编码格式为 utf-8，不排除其他编码格式的可能，转成 str 以后，理想状态下我们希望它是 json 字符串，使用 <code>json.loads()</code> 方法很方便就可以解析出来。遗憾的是需要爬取数据的网站大部分是不提供或者不对外提供 json 接口，因此我们只能解析 HTML 文本。Python 自带的 HTML 解析库比较不方便使用，在开发爬虫工具的过程中接触了两个第三方库： <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="external">Beautiful Soup</a> 和 <a href="http://lxml.de/" target="_blank" rel="external">lxml</a>。</p>
<p>Beautiful Soup 支持不同的解析器，包括 Python 标准库、lxml、html5lib，不过捣鼓了半天愣是没学会怎么用 BS 基于 lxml 支持的 xpath 来提取所需节点，最终选择直接用 lxml 来解析 HTML 文本。</p>
<p>lxml 的安装还是挺纠结的，笔者觉得除了缺少梯子的问题，它的文档都是英文的也是个问题，最终是通过 Anaconda Navigator 安装上的，如果读者有好的安装方法，麻烦花点时间给笔者留个言。</p>
<p>附上一个解析HTML的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</div><div class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</div><div class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">requestImcreator</span><span class="params">(pageIndex, pageSize=<span class="number">0</span>)</span>:</span></div><div class="line">    url = <span class="string">'http://imcreator.com/index.php'</span></div><div class="line">    body = <span class="string">'ajax_load_img=load&amp;m_cat_id=19&amp;page=%d'</span> % pageIndex</div><div class="line">    data = body.encode(encoding=<span class="string">'utf_8'</span>)</div><div class="line">    req = request.Request(url, data)</div><div class="line">    <span class="keyword">with</span> request.urlopen(req) <span class="keyword">as</span> f:</div><div class="line">        response = f.read().decode(<span class="string">'utf-8'</span>)</div><div class="line">        <span class="keyword">return</span> _serializerImcreator(response)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_serializerImcreator</span><span class="params">(response)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        tree = etree.HTML(response)</div><div class="line">        elements = tree.xpath(<span class="string">'//div[@class="box"]/a'</span>)</div><div class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">        print(<span class="string">'serializerImcreator except: '</span>, e)</div><div class="line">        <span class="keyword">raise</span> e</div><div class="line">    <span class="keyword">finally</span>:</div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(elements) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> []</div><div class="line"></div><div class="line">    result = []</div><div class="line"></div><div class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> elements:</div><div class="line">        detailURL = a.get(<span class="string">'href'</span>)</div><div class="line">        h4s = a.xpath(<span class="string">'div/div/h4'</span>)</div><div class="line">        title = <span class="keyword">None</span></div><div class="line">        <span class="keyword">if</span> len(h4s) &gt; <span class="number">0</span>:</div><div class="line">            title = h4s[<span class="number">0</span>].text</div><div class="line"></div><div class="line">        result.append(&#123;<span class="string">'url'</span>: detailURL,</div><div class="line">                       <span class="string">'title'</span>: title&#125;)</div><div class="line">    <span class="keyword">return</span> result</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    print(requestImcreator(<span class="number">1</span>, <span class="number">2</span>))</div></pre></td></tr></table></figure>
<p>从上面的例子可以看到 tree 通过 <code>xpath()</code> 检索出来的 element 可以继续调用 <code>xpath()</code> 方法查找指定节点。</p>
<p>XPath 是一门在 XML 文档中查找信息的语言，可用来在 XML 文档中对元素和属性进行遍历，有点类似css的选择器，详细的语法请移步<a href="http://www.w3school.com.cn/xpath/" target="_blank" rel="external">XPath教程</a>。</p>
<p>通过 Chrome 浏览器可以很快得到我们需要的 XPath 路径：</p>
<p><img src="Snip20160902_8.png" alt=""></p>
<p>这个方法可以得到大部分我们需要的或者接近需要的 xpath，但是笔者目前知道的有一种例外情况，那就是伪元素，包含伪元素的 xpath 路径，通常无法正常解析出目标元素，只能检索到伪元素的上层元素，再通过遍历的手段获取到所需的目标元素。</p>
<h1 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h1><p>爬虫中的 Cookie 的操作主要是为了存储登录信息，遗憾的是模拟登录表单、缓存、上报 Cookie 都还不会，此处只能留白了。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://codingpub.github.io/2016/09/05/Python爬虫入门-网络请求/" data-id="cj56nwguw000u8qrmcp0mexxq" class="article-share-link">分享到</a><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-nav"><a href="/2016/09/05/Python爬虫入门-数据存储/" class="pre">Python爬虫入门-数据存储</a><a href="/2016/09/05/Python爬虫入门-进阶知识/" class="next">Python爬虫入门-进阶知识</a></div><div id="disqus_thread"><script>var disqus_shortname = 'codingpub';
var disqus_identifier = '2016/09/05/Python爬虫入门-网络请求/';
var disqus_title = 'Python爬虫入门-网络请求';
var disqus_url = 'http://codingpub.github.io/2016/09/05/Python爬虫入门-网络请求/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//codingpub.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Google Search"/><input type="hidden" name="sitesearch" value="http://codingpub.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/iOS/">iOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发工具/">开发工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/跨平台开发/">跨平台开发</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/VS-Code/" style="font-size: 15px;">VS Code</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/OS-X/" style="font-size: 15px;">OS X</a> <a href="/tags/网络接口/" style="font-size: 15px;">网络接口</a> <a href="/tags/Fiddler/" style="font-size: 15px;">Fiddler</a> <a href="/tags/博客/" style="font-size: 15px;">博客</a> <a href="/tags/Sublime-Text/" style="font-size: 15px;">Sublime Text</a> <a href="/tags/React-Native/" style="font-size: 15px;">React Native</a> <a href="/tags/Universal-Link/" style="font-size: 15px;">Universal Link</a> <a href="/tags/iOS9/" style="font-size: 15px;">iOS9</a> <a href="/tags/ATS/" style="font-size: 15px;">ATS</a> <a href="/tags/Xcode/" style="font-size: 15px;">Xcode</a> <a href="/tags/微信小程序/" style="font-size: 15px;">微信小程序</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/07/16/VS-Code-for-markdown/">VS Code for markdown</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/16/VS-Code-for-Python/">VS Code for Python</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/10/VS-Code/">VS Code</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/09/RN初体验之环境篇/">RN初体验之环境篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/22/微信小程序瀑布流的实现和内存优化/">微信小程序瀑布流的实现和内存优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/10/27/OS-X-添加定时任务/">OS X 添加定时任务</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/07/更新Hexo3-x报错/">更新Hexo 3.x 报错</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/05/PrettyTable/">PrettyTable</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/05/Python爬虫入门-打包程序/">Python爬虫入门-打包程序</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/05/Python爬虫入门-多线程/">Python爬虫入门-多线程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//codingpub.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Coding Pub.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-76019304-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?8c93fd4ddef9e7d0dbe65a2f1be22919";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>