<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="description" content="喜欢在夜深人静的时候敲键盘">



<title>Python爬虫入门-网络请求 | Coding Pub</title>






    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


</head>
<body>
    <div class="wrapper">
        <header>
  <nav class="navbar">
    <div class="container">
      <div class="navbar-header header-logo">
        <a href="/">CodingPub&#39;s Blog</a>
      </div>
      <div class="menu navbar-right">
        
        <a class="menu-item" href="/archives">Posts</a>
        
        <a class="menu-item" href="/category">Categories</a>
        
        <a class="menu-item" href="/tag">Tags</a>
        
        <a class="menu-item" href="/about">About</a>
        

        <form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
          <input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search">
          <input type="hidden" name="q" value="site:codingpub.github.io">
        </form>

        <input id="switch_default" type="checkbox" class="switch_default">
        <label for="switch_default" class="toggleBtn"></label>
      </div>
    </div>
  </nav>

  
  <nav class="navbar-mobile" id="nav-mobile">
    <div class="container">
      <div class="navbar-header">
        <div>
          <a href="/">CodingPub&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
        </div>
        <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
      </div>
      <div class="menu" id="mobile-menu">
        
        <a class="menu-item" href="/archives">Posts</a>
        
        <a class="menu-item" href="/category">Categories</a>
        
        <a class="menu-item" href="/tag">Tags</a>
        
        <a class="menu-item" href="/about">About</a>
        
      </div>
    </div>
  </nav>
</header>
<script>
  var mobileBtn = function f() {
    var toggleMenu = document.getElementsByClassName('menu-toggle')[0]
    var mobileMenu = document.getElementById('mobile-menu')
    if (toggleMenu.classList.contains('active')) {
      toggleMenu.classList.remove('active')
      mobileMenu.classList.remove('active')
    } else {
      toggleMenu.classList.add('active')
      mobileMenu.classList.add('active')
    }
  }
</script>

        <div class="main">
            <div class="container">
    <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>  
  <article class="post-wrap">
    <header class="post-header">
      <h1 class="post-title">Python爬虫入门-网络请求</h1>
      
      <div class="post-meta">
         Author:
        <a itemprop="author" rel="author" href="/">Xiaobin, Lin</a>
         
        <span class="post-time">
          Date: <a href="#">2016-09-05</a>
        </span>
         
        <span class="post-category">
          Category: 
          <a href="/categories/Python/">Python</a>
          
        </span>
        
      </div>
      
    </header>

    <div class="post-content">
      <p>介绍了许多语法基础，我们终于可以进入爬虫开发的正文了，就爬虫工具而言，Python对比于其他的语言有很大的优势，它内置的模块提供了强大的网络请求、数据处理功能。</p>
<a id="more"></a>

<h1 id="URL-Operation"><a href="#URL-Operation" class="headerlink" title="URL Operation"></a>URL Operation</h1><p>URL 作为网络请求最基础的部分，这里需要介绍一下 Python 的 URL 处理。</p>
<h2 id="编码-amp-解码"><a href="#编码-amp-解码" class="headerlink" title="编码 &amp; 解码"></a>编码 &amp; 解码</h2><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">url = <span class="string">'https://www.test.com/photos?order_by=latest&amp;page=%d&amp;per_page=%d'</span> <span class="meta">%</span> <span class="comment">(pageIndex, pageSize)</span></span><br></pre></td></tr></table></figure>

<p>这是最简单的字符串拼接方式，在前面也有提过，不再展开。</p>
<p>假如我们有一个dict需要转成 URL 的 query 字符串，可以使用下面的方法：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import urllib.parse</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">values</span> = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</span><br><span class="line">...           <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</span><br><span class="line">...           <span class="string">'title'</span>: <span class="string">'标题'</span>,</span><br><span class="line">...           <span class="string">'sourceId'</span>: <span class="number">10</span>,</span><br><span class="line">...           <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; query = urllib.parse.urlencode(<span class="keyword">values</span>)</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">print</span>(query)</span><br><span class="line">action=InsertPicReptile&amp;sourceId=<span class="number">10</span>&amp;title=%E6%A0%87%E9%A2%98&amp;url=http%3A%2F%2Fwww.google.com&amp;uniqueId=<span class="number">1122</span></span><br></pre></td></tr></table></figure>

<p>你是不是注意到有一些字符被自动转码为带有<code>%</code>的格式，除了这个，urllib.parse 还提供了其他的方法：</p>
<ul>
<li><p>quote(string, safe=’/‘, encoding=None, errors=None)</p>
<p>  对字符串进行编码，参数 safe 指定了不需要编码的字符</p>
</li>
<li><p>unquote(string, encoding=’utf-8’, errors=’replace’)</p>
<p>  对字符串进行解码</p>
</li>
<li><p>quote_plus(string, safe=’’, encoding=None, errors=None)</p>
<p>  与 quote 类似，但这个方法用<code>&#39;+&#39;</code>来替换<code>&#39; &#39;</code>，而 quote 用<code>&#39;%20&#39;</code>来代替<code>&#39; &#39;</code></p>
</li>
<li><p>unquote_plus(string, encoding=’utf-8’, errors=’replace’)</p>
<p>  对字符串进行解码</p>
</li>
<li><p>urlencode(query, doseq=False, safe=’’, encoding=None, errors=None, quote_via=&lt;function quote_plus at 0x10147ff28&gt;)</p>
<p>  将dict或者包含两个元素的元组列表转换成url参数</p>
</li>
</ul>
<h2 id="解析-URL"><a href="#解析-URL" class="headerlink" title="解析 URL"></a>解析 URL</h2><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; from urllib import parse</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; url = <span class="string">"http://www.baidu.com/s?wd=codeif.com&amp;rsv_spt=1&amp;issp=1&amp;rsv_bp=0&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_sug3=4&amp;rsv_sug=1&amp;rsv_sug1=3&amp;rsv_sug4=74"</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; o = parse.urlparse(url)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; print(<span class="string">'URL detail:'</span>, o)</span><br><span class="line">URL <span class="symbol">detail:</span> ParseResult(scheme=<span class="string">'http'</span>, netloc=<span class="string">'www.baidu.com'</span>, path=<span class="string">'/s'</span>, params=<span class="string">''</span>, query=<span class="string">'wd=codeif.com&amp;rsv_spt=1&amp;issp=1&amp;rsv_bp=0&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_sug3=4&amp;rsv_sug=1&amp;rsv_sug1=3&amp;rsv_sug4=74'</span>, fragment=<span class="string">''</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; params = parse.parse_qs(o.query)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; print(<span class="string">'URL query:'</span>, params)</span><br><span class="line">URL <span class="symbol">query:</span> &#123;<span class="string">'rsv_spt'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_sug3'</span>: [<span class="string">'4'</span>], <span class="string">'ie'</span>: [<span class="string">'utf-8'</span>], <span class="string">'issp'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_bp'</span>: [<span class="string">'0'</span>], <span class="string">'rsv_sug4'</span>: [<span class="string">'74'</span>], <span class="string">'tn'</span>: [<span class="string">'baiduhome_pg'</span>], <span class="string">'wd'</span>: [<span class="string">'codeif.com'</span>], <span class="string">'rsv_sug'</span>: [<span class="string">'1'</span>], <span class="string">'rsv_sug1'</span>: [<span class="string">'3'</span>]&#125;</span><br></pre></td></tr></table></figure>

<h1 id="发起请求"><a href="#发起请求" class="headerlink" title="发起请求"></a>发起请求</h1><p>一个完整的网络请求、解析过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">requestUnsplash</span><span class="params">(pageIndex, pageSize)</span>:</span></span><br><span class="line">    url = <span class="string">'https://unsplash.com/napi/photos?order_by=latest&amp;page=%d&amp;per_page=%d'</span> % (pageIndex, pageSize)</span><br><span class="line"></span><br><span class="line">    headers = &#123;<span class="string">'accept-version'</span>: <span class="string">'v1'</span>,</span><br><span class="line">               <span class="string">'authorization'</span>: <span class="string">'Client-ID d69927c7ea5c770fa2ce9a2f1e3589bd896454f7068f689d8e41a25b54fa6042'</span>,</span><br><span class="line">               <span class="string">'Referer'</span>: <span class="string">'https://unsplash.com/new'</span>,</span><br><span class="line">               <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'</span>&#125;</span><br><span class="line"></span><br><span class="line">    req = request.Request(url, data=<span class="literal">None</span>, headers=headers, origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>, method=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> request.urlopen(req) <span class="keyword">as</span> f:</span><br><span class="line">        response = f.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="comment"># print(f.info())</span></span><br><span class="line">        <span class="keyword">return</span> json.loads(response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(requestUnsplash(1, 5))</span></span><br></pre></td></tr></table></figure>

<h2 id="Request-Header"><a href="#Request-Header" class="headerlink" title="Request Header"></a>Request Header</h2><p>从上面的代码可以到在初始化 Request 的时候可以传递 headers、data 参数，其中 header 是 dict 对象，data 是 body 编码后的 bytes 数据。</p>
<p>在初始化 Request 之后，还可以通过下面的方法设置 Header 参数。</p>
<figure class="highlight ceylon"><table><tr><td class="code"><pre><span class="line">req.add<span class="number">_</span>header(kye, <span class="keyword">value</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Request-Body"><a href="#Request-Body" class="headerlink" title="Request Body"></a>Request Body</h2><p>要传递的 body 可以是表单形式，也可以是 json 格式，最终都是字符串编码为 bytes 数据流，文件表单这里不做讨论，用的比较少。</p>
<ul>
<li><p>表单形式的 body</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>values = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'title'</span>: <span class="string">'标题'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'sourceId'</span>: <span class="number">10</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = parse.urlencode(values)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = body.encode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(data)</span><br><span class="line"><span class="string">b'action=InsertPicReptile&amp;sourceId=10&amp;title=%E6%A0%87%E9%A2%98&amp;url=http%3A%2F%2Fwww.google.com&amp;uniqueId=1122'</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>json 形式的 body</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> json</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>values = &#123;<span class="string">'action'</span>: <span class="string">'InsertPicReptile'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'url'</span>: <span class="string">'http://www.google.com'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'title'</span>: <span class="string">'标题'</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'sourceId'</span>: <span class="number">10</span>,</span><br><span class="line"><span class="meta">... </span>          <span class="string">'uniqueId'</span>: <span class="number">1122</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>body = json.dumps(values)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>data = body.encode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(data)</span><br><span class="line"><span class="string">b'&#123;"action": "InsertPicReptile", "sourceId": 10, "title": "\\u6807\\u9898", "url": "http://www.google.com", "uniqueId": 1122&#125;'</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="MD5"><a href="#MD5" class="headerlink" title="MD5"></a>MD5</h2><p>接口请求经常会在Header或URL参数上增加校验参数，MD5加密算法是比较常用的不对成加密算法。Python已经封装了常用的加密算法，这里以MD5为例：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; import hashlib</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; md5Str = <span class="string">'key=hello'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; sign = hashlib.md5(md5Str.encode(<span class="string">'utf-8'</span>)).hexdigest()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; print(sign)</span><br><span class="line"><span class="number">5</span>be7dcd8127f86af33182c778f27a185</span><br></pre></td></tr></table></figure>

<h2 id="Response-Header"><a href="#Response-Header" class="headerlink" title="Response Header"></a>Response Header</h2><p>前文完整的请求示例中屏蔽掉的 <code>print(f.info())</code> 可以用于获取 HTTP 请求的 Response Header。</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># 提取 Header 信息</span><br><span class="line">resHeaders = <span class="keyword">f</span>.info()</span><br><span class="line"><span class="built_in">keys</span> = resHeaders.<span class="built_in">keys</span>()</span><br><span class="line"><span class="built_in">values</span> = resHeaders.<span class="built_in">values</span>()</span><br><span class="line"><span class="built_in">items</span> = resHeaders.<span class="built_in">items</span>()</span><br><span class="line"><span class="keyword">print</span>(<span class="string">'keys:'</span>, <span class="built_in">keys</span>, <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="string">'values:'</span>, <span class="built_in">values</span>, <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="string">'items:'</span>, <span class="built_in">items</span>, <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"># 提取 HTTP 请求状态码</span><br><span class="line"><span class="keyword">print</span>(<span class="string">'status:'</span>, <span class="keyword">f</span>.getcode())</span><br></pre></td></tr></table></figure>

<h2 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h2><p>body 读取出来是 bytes 数据，需要经过编码转成 str，目前主流编码格式为 utf-8，不排除其他编码格式的可能，转成 str 以后，理想状态下我们希望它是 json 字符串，使用 <code>json.loads()</code> 方法很方便就可以解析出来。遗憾的是需要爬取数据的网站大部分是不提供或者不对外提供 json 接口，因此我们只能解析 HTML 文本。Python 自带的 HTML 解析库比较不方便使用，在开发爬虫工具的过程中接触了两个第三方库： <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="noopener">Beautiful Soup</a> 和 <a href="http://lxml.de/" target="_blank" rel="noopener">lxml</a>。</p>
<p>Beautiful Soup 支持不同的解析器，包括 Python 标准库、lxml、html5lib，不过捣鼓了半天愣是没学会怎么用 BS 基于 lxml 支持的 xpath 来提取所需节点，最终选择直接用 lxml 来解析 HTML 文本。</p>
<p>lxml 的安装还是挺纠结的，笔者觉得除了缺少梯子的问题，它的文档都是英文的也是个问题，最终是通过 Anaconda Navigator 安装上的，如果读者有好的安装方法，麻烦花点时间给笔者留个言。</p>
<p>附上一个解析HTML的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">requestImcreator</span><span class="params">(pageIndex, pageSize=<span class="number">0</span>)</span>:</span></span><br><span class="line">    url = <span class="string">'http://imcreator.com/index.php'</span></span><br><span class="line">    body = <span class="string">'ajax_load_img=load&amp;m_cat_id=19&amp;page=%d'</span> % pageIndex</span><br><span class="line">    data = body.encode(encoding=<span class="string">'utf_8'</span>)</span><br><span class="line">    req = request.Request(url, data)</span><br><span class="line">    <span class="keyword">with</span> request.urlopen(req) <span class="keyword">as</span> f:</span><br><span class="line">        response = f.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="keyword">return</span> _serializerImcreator(response)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_serializerImcreator</span><span class="params">(response)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tree = etree.HTML(response)</span><br><span class="line">        elements = tree.xpath(<span class="string">'//div[@class="box"]/a'</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">'serializerImcreator except: '</span>, e)</span><br><span class="line">        <span class="keyword">raise</span> e</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(elements) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> elements:</span><br><span class="line">        detailURL = a.get(<span class="string">'href'</span>)</span><br><span class="line">        h4s = a.xpath(<span class="string">'div/div/h4'</span>)</span><br><span class="line">        title = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> len(h4s) &gt; <span class="number">0</span>:</span><br><span class="line">            title = h4s[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">        result.append(&#123;<span class="string">'url'</span>: detailURL,</span><br><span class="line">                       <span class="string">'title'</span>: title&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(requestImcreator(<span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<p>从上面的例子可以看到 tree 通过 <code>xpath()</code> 检索出来的 element 可以继续调用 <code>xpath()</code> 方法查找指定节点。</p>
<p>XPath 是一门在 XML 文档中查找信息的语言，可用来在 XML 文档中对元素和属性进行遍历，有点类似css的选择器，详细的语法请移步<a href="http://www.w3school.com.cn/xpath/" target="_blank" rel="noopener">XPath教程</a>。</p>
<p>通过 Chrome 浏览器可以很快得到我们需要的 XPath 路径：</p>
<p><img src="Snip20160902_8.png" alt></p>
<p>这个方法可以得到大部分我们需要的或者接近需要的 xpath，但是笔者目前知道的有一种例外情况，那就是伪元素，包含伪元素的 xpath 路径，通常无法正常解析出目标元素，只能检索到伪元素的上层元素，再通过遍历的手段获取到所需的目标元素。</p>
<h1 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h1><p>爬虫中的 Cookie 的操作主要是为了存储登录信息，遗憾的是模拟登录表单、缓存、上报 Cookie 都还不会，此处只能留白了。</p>

    </div>

    
    <section class="post-copyright">
      
      <p class="copyright-item">
        <span>Author:</span>
        <span>Xiaobin, Lin</span>
      </p>
       
      <p class="copyright-item">
        <span>Permalink:</span>
        <span><a href="http://codingpub.github.io/2016/09/05/Python爬虫入门-网络请求/">http://codingpub.github.io/2016/09/05/Python爬虫入门-网络请求/</a></span>
      </p>
       
      <p class="copyright-item">
        <span>License:</span>
        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
      </p>
       
    </section>
    
    <section class="post-tags">
      <div>
        <span>Tag(s):</span>
        <span class="tag">
           
          <a href="/tags/爬虫/"># 爬虫</a>
           
        </span>
      </div>
      <div>
        <a href="javascript:window.history.back();">back</a>
        <span>· </span>
        <a href="/">home</a>
      </div>
    </section>
    <section class="post-nav">
      
      <a class="prev" rel="prev" href="/2016/09/05/Python爬虫入门-数据存储/">Python爬虫入门-数据存储</a>
       
      <a class="next" rel="next" href="/2016/09/05/Python爬虫入门-进阶知识/">Python爬虫入门-进阶知识</a>
      
    </section>
  </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Xiaobin, Lin | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
